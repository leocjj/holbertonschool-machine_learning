# Holberton School - Machine learning

## 0x01. Classification
### Resources

Read or watch:

    Supervised vs. Unsupervised Machine Learning
    How would you explain neural networks to someone who knows very little about AI or neurology?
    Using Neural Nets to Recognize Handwritten Digits (until “A simple network to classify handwritten digits” (excluded))
    Forward propagation
    Understanding Activation Functions in Neural Networks
    Loss function
    Gradient descent
    Calculus on Computational Graphs: Backpropagation
    Backpropagation calculus
    What is a Neural Network?
    Supervised Learning with a Neural Network
    Binary Classification
    Logistic Regression
    Logistic Regression Cost Function
    Gradient Descent
    Computation Graph
    Logistic Regression Gradient Descent
    Vectorization
    Vectorizing Logistic Regression
    Vectorizing Logistic Regression’s Gradient Computation
    A Note on Python/Numpy Vectors
    Neural Network Representations
    Computing Neural Network Output
    Vectorizing Across Multiple Examples
    Gradient Descent For Neural Networks
    Random Initialization
    Deep L-Layer Neural Network
    Train/Dev/Test Sets
    Random Initialization For Neural Networks : A Thing Of The Past
    Initialization of deep networks
    Multiclass classification
    Derivation: Derivatives for Common Neural Network Activation Functions
    What is One Hot Encoding? Why And When do you have to use it?
    Softmax function
    What is the intuition behind SoftMax function?
    Cross entropy
    Loss Functions: Cross-Entropy
    Softmax Regression (Note: I suggest watching this video at 1.5x - 2x speed)
    Training Softmax Classifier (Note: I suggest watching this video at 1.5x - 2x speed)
    numpy.zeros
    numpy.random.randn
    numpy.exp
    numpy.log
    numpy.sqrt
    numpy.where
    numpy.max
    numpy.sum
    numpy.argmax
    What is Pickle in python?
    pickle
    pickle.dump
    pickle.load

Optional:

    Predictive analytics
    Maximum Likelihood Estimation



### Learning Objectives

At the end of this project, you are expected to be able to explain to anyone, without the help of Google:

    What is a model?
    What is supervised learning?
    What is a prediction?
    What is a node?
    What is a weight?
    What is a bias?
    What are activation functions?
        Sigmoid?
        Tanh?
        Relu?
        Softmax?
    What is a layer?
    What is a hidden layer?
    What is Logistic Regression?
    What is a loss function?
    What is a cost function?
    What is forward propagation?
    What is Gradient Descent?
    What is back propagation?
    What is a Computation Graph?
    How to initialize weights/biases
    The importance of vectorization
    How to split up your data
    What is multiclass classification?
    What is a one-hot vector?
    How to encode/decode one-hot vectors
    What is the softmax function and when do you use it?
    What is cross-entropy loss?
    What is pickling in Python?

## Requirementes

    The first line of all your files should be exactly #!/usr/bin/env python3
    A README.md file, at the root of the folder of the project, is mandatory
    Your code should use the pycodestyle style (version 2.4)
    All your modules should have documentation (python3 -c 'print(__import__("my_module").__doc__)')
    All your classes should have documentation (python3 -c 'print(__import__("my_module").MyClass.__doc__)')
    All your functions (inside and outside a class) should have documentation (python3 -c 'print(__import__("my_module").my_function.__doc__)' and python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)')
    Unless otherwise noted, you are not allowed to import any module except import numpy as np
    Unless otherwise noted, you are not allowed to use any loops (for, while, etc.)
    All your files must be executable

## Execution
- To execute examples for each task, run the *xx-main.py* file related.
- Download training files from ../data/ (i.e.: Binary_Train.npz, Binary_Dev.npz, MNIST.npz)
- For tasks 27 and 28, download trained models from:
https://s3.amazonaws.com/intranet-projects-files/holbertonschool-ml/27-saved.pkl
  and
  https://s3.amazonaws.com/intranet-projects-files/holbertonschool-ml/28-saved.pkl


## Tasks

0. Neuron
1. Privatize Neuron
2. Neuron Forward Propagation
3. Neuron Cost
4. Evaluate Neuron
5. Neuron Gradient Descent
6. Train Neuron
7. Upgrade Train Neuron **(perceptron)**


8. NeuralNetwork
9. Privatize NeuralNetwork
10. NeuralNetwork Forward Propagation
11. NeuralNetwork Cost
12. Evaluate NeuralNetwork
13. NeuralNetwork Gradient Descent
14. Train NeuralNetwork
15. Upgrade Train NeuralNetwork **(one layer binary classification)**


16. DeepNeuralNetwork
17. Privatize DeepNeuralNetwork
18. DeepNeuralNetwork Forward Propagation
19. DeepNeuralNetwork Cost
20. Evaluate DeepNeuralNetwork
21. DeepNeuralNetwork Gradient Descent
22. Train DeepNeuralNetwork
23. Upgrade Train DeepNeuralNetwork **(binary classificator)**
23b. Upgrade Train DeepNeuralNetwork **(binary classificator with LOGMOID activation function)**


24. One-Hot Encode
25. One-Hot Decode


26. Persistence is Key (pickle)


27. Update DeepNeuralNetwork
28. All the Activations **(multiclass classification)**

29. Activation functions:
https://www.linkedin.com/pulse/activation-functions-neural-networks-leonardo-calderon-j-


## Built With

* Python 3.6
* Pycharm 2021
* PycodeStyle

## Author

**Leonardo Calderon J.** - *Initial work* 

## [LeoCJJ](https://github.com/leocjj)

[Web Page](http://leocjj.tech)

2021
